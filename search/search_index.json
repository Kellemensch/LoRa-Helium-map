{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Lora-Helium-Map Documentation","text":"<p>For full project detail visit the GitHub page.</p>"},{"location":"#project-overview","title":"Project overview","text":"<p>LoRa-Helium-Map is a Python toolkit to retrieve real-time data from a LoRaWAN end-node connected to the Helium Network, process radiosonde observations (IGRA v2 or ERA5), compute atmospheric refractivity gradients, visualize potential tropospheric ducts, and make statistics.</p> <p>This project is a continuation of the previous project done by Abdus Salam International Centre for Theoretical Physics (ICTP) researchers Pr. Marco Zennaro, Pr. Ermanno Pietrosemoli and Pr. Marco Rainone. See their paper here.</p> <p>It was also based on their project TAT.py: Tropospheric Analysis Tools in Python. See their paper here.</p> <p>This project is built on the Helium Network, a global decentralized LoRaWAN infrastructure. After initial testing with The Things Network (TTN), Helium was chosen due to its significantly larger community and higher density of gateways, which improves the chances of capturing and analyzing signals over long distances. This broader coverage is particularly important to our research focus: studying abnormal radio wave propagation in the troposphere, a phenomenon that can extend communication ranges far beyond normal line-of-sight limits.</p> <p>The motivation behind this work is to better understand how environmental conditions in the lower atmosphere influence long-range wireless communications. While LoRaWAN networks are typically designed for predictable line-of-sight coverage, rare tropospheric phenomena\u2014such as ducting\u2014can create unexpected, extended communication links. By systematically collecting and correlating real-world network data with atmospheric measurements, this project aims to identify, quantify, and visualize these events. The resulting insights could help refine radio propagation models, assist network planners in optimizing infrastructure, and contribute to the broader scientific study of atmospheric effects on wireless technologies.</p>"},{"location":"#latest-release","title":"Latest release","text":"<p>You can find the documentation of the latest release for this project here.</p>"},{"location":"README_docker/","title":"LoRa-Helium-Map \u2013 Installation &amp; Configuration Guide (Docker)","text":""},{"location":"README_docker/#requirements","title":"Requirements","text":"<p>Your computer or server must have an active internet connection to download dependencies and receive Helium network data.</p>"},{"location":"README_docker/#docker-installation","title":"Docker installation","text":"<p>This application requires Docker to run in a containerized environment. It is recommended to use a Debian-based OS (such as Ubuntu), but it can also work on Windows or macOS. See the documentation on how to install at : https://docs.docker.com/engine/install/</p> <p>Installation for Windows</p> <p>Or if you want a fast and automatic script which self download the proper version on your OS, see : get-docker</p> <p>Once installed, test Docker by running : <pre><code>docker --version\ndocker run --rm hello-world\n</code></pre></p>"},{"location":"README_docker/#helium-network-setup","title":"Helium network setup","text":"<p>To receive LoRa data, you must register your device with the Helium network.</p> <ol> <li>Register an account on the console : this is your main console where you can see all your registered devices and applications</li> <li>Go to <code>Applications</code> on the left side menu</li> <li>Click on <code>Add application</code> and fill the name you want</li> <li>Go to <code>Device Profiles</code> and click <code>Add</code>.</li> <li>Enter a name.</li> <li>Choose the correct MAC version (e.g. 1.0.3 for LoRa-E5).</li> <li>Choose the proper Regional Parameters (e.g. RP002-1.0.3 - EU868).</li> <li>Revision: B</li> <li>Expected uplink interval: <code>360</code></li> <li>Device-status request frequency: <code>1</code></li> <li>RX1 Delay: <code>0</code></li> <li>Enable \u201cFlush queue on activation\u201d</li> <li>Select the Default ADR algorithm</li> <li>Select OTAA or ABP, depending on your device</li> <li>Back in your Application, click <code>Add Device</code>.</li> <li>Enter a device name</li> <li>Provide the DevEUI (on your device label)</li> <li>Use <code>\"0000000000000000\"</code> as the Join EUI</li> <li>Choose the device profile you just created</li> <li>Click <code>Create</code></li> <li>Now, you need to configure your LoRa module to connect to the network using AT commands (you can generate a AppKey from your device in your application on the console), please put the good EUI and AppKey :</li> </ol> <p><pre><code>AT+ID=DevEui,\"put your EUI here\"\nAT+KEY=APPKEY,\"put your AppKey here\"\nAT+DR=EU868 \\\\ OR 915 for USA\nAT+JOIN\n</code></pre> 8.  Upon succes, you should see : <pre><code>+JOIN: Network joined successfully\n</code></pre></p>"},{"location":"README_docker/#http-integration-in-helium-console","title":"HTTP integration in Helium Console","text":"<p>Now that you have registered your device on the Helium Network, you will need to create an HTTP integration in order to retrieve data with the LoRa-Helium-map application.</p> <ol> <li>In the Helium Console, go to <code>Applications</code> \u2192 your app \u2192 <code>Integrations</code>.</li> <li>Click <code>Add Integration</code>, then choose <code>HTTP</code>.</li> <li>Set:</li> <li>Payload encoding: <code>JSON</code></li> <li>Endpoint URL: your localtunnel URL, ending with <code>/helium-data</code>      Example: <code>https://yourlaboratory.loca.lt/helium-data</code></li> <li>Headers:<ul> <li>Key: <code>Content-Type</code></li> <li>Value: <code>application/json</code></li> </ul> </li> <li>Click <code>Create Integration</code></li> </ol>"},{"location":"README_docker/#download","title":"Download","text":"<p>Download the latest version here and unzip the package.</p>"},{"location":"README_docker/#launch","title":"Launch","text":"<p>To launch the application you must know your end-device's latitude and longitude in degrees, and you url subdomain (in the example above : yourlaboratory)</p> <p>If you are on Linux, you can then launch the application by simply typing : <pre><code>./run.sh\n</code></pre> You will be asked to provide the latitude, longitude and subdomain.</p> <p>It will then automatically download terrain files around your end-device's place and begin to retrieve data from the Helium Network.</p> <p>It is recommended to leave the application running all day and night long on a running server in order to get the maximum of data.</p>"},{"location":"README_docker/#results","title":"Results","text":"<p>Results can be found in the <code>output/</code> folder in your current directory.</p> <p>The application writes every 5 minutes a map in <code>output/map.html</code> using the Splat! tool.</p> <p>It also runs twice a day (every 12 hours) an IGRA calculation using radiosonde balloons observations. It is important to note that new data from this dataset is not necessary available everyday, so you might wait a few days before new data are available and processed by the application.</p> <p>Be aware that all the dataset retrieved from you Helium end-node is stored in <code>output/data/helium_gateway_data.csv</code> and that no other version of this file does exist elsewhere. You might want to do regular saves of this file on another disk for backup (old data cannot be retrieved anymore).</p> <p>Finally, you can see the resulted map on your dedicated website ! It is available at the address with the subdomain you chose : <code>http://subdomain.loca.lt/map</code>, for example : <code>http://yourlaboratory.loca.lt/map</code></p> <p>Logs are available with the command : <code>docker logs -f lora-map</code> You can stop the application with the command : <code>docker compose down</code></p> <p>A container named <code>watchtower</code> is used to pull updates of this application from the cloud. If an update is available, the application will be restarted without destroying any file and dataset.</p> <p>If the tunnel is unavailable, don't panic, it will be relaunched automatically by the application. It is probably due to localtunnel's servers, it might take some time. If the problem still persists, be sure that your connection to internet is authorized.</p>"},{"location":"README_docker/#documentation","title":"Documentation","text":"<p>You can find all the documentation for the files in the dedicated section.</p>"},{"location":"author/","title":"Author","text":"<p>This project was created by Baptiste Demoisy during his internship at the Abdus Salam International Centre Theoritical Physics.</p> <p>This project was conducted by Pr. Marco Zennaro with help of the STI Unit and the MarconiLab people.</p> <p>It would never have been possible without Pr. Ermanno Pietrosemoli, Pr. Marco Rainone, Pr. Rytis Paskauskas.</p>"},{"location":"docker_documentation/","title":"Docker Documentation","text":"<p>The Docker repository can be found in DockerHub here.</p> <p>For setup and installation, see this section</p>"},{"location":"docker_documentation/#containers-used","title":"Containers used","text":"<p>This project uses a total of 2 containers:</p> <ul> <li>The application <code>app</code> : from main repository <code>kellemensch/lora-helium-map:latest</code></li> <li>A Watchtower to automate updates: from <code>containrrr/watchtower</code> - See GitHub repo</li> </ul>"},{"location":"docker_documentation/#available-files","title":"Available files","text":""},{"location":"docker_documentation/#docker-composeyaml","title":"docker-compose.yaml","text":"<pre><code>services:\n  app:\n    build:\n      context: .\n      args:\n        USER_ID: ${LOCAL_UID}\n        GROUP_ID: ${LOCAL_GID}\n    image: kellemensch/lora-helium-map:latest\n    container_name: lora-map\n    ports:\n      - \"5000:5000\"\n    volumes:\n      - ./output:/app/output\n      - ./configs:/app/configs\n    restart: unless-stopped\n\n  watchtower:\n    image: containrrr/watchtower\n    container_name: watchtower\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    environment:\n      - WATCHTOWER_CLEANUP=true\n      - WATCHTOWER_POLL_INTERVAL=300  # Every 5 minutes\n    restart: unless-stopped\n</code></pre> <p>The <code>docker-compose</code> file starts these two containers by making sure the output files created by the application are user files and not root files (in order to keep it rootless). </p> <p>Then it creates two volumes:</p> <ul> <li><code>output/</code> folder to save and plot the results</li> <li><code>configs/</code> folder containing the python module that returns the end-node's coordinates</li> </ul>"},{"location":"docker_documentation/#runsh","title":"run.sh","text":"<p>This scripts automates the configuration for the docker. It makes you create the coordinates of your end-node and the subdomain you want to use for your webhook (same as the one in Helium integration) and for the website exposure.</p> <p>The coordinates are written into <code>configs/.latitude</code> and <code>configs/.longitude</code>, and the subdomain into <code>configs/.subdomain</code>.</p> <p>Then it sets two environment variables <code>LOCAL_UID</code> and <code>LOCAL_GID</code> so that Docker can retrieve them from the docker-compose.</p> <p>Finally, it launches the pull from DockerHub and starts the containers.</p>"},{"location":"docker_documentation/#files-in-docker-application-image","title":"Files in Docker application image","text":""},{"location":"docker_documentation/#mainpy","title":"main.py","text":"<p>The main script running all processes. At first launch, it runs all the useful files:</p> <ul> <li><code>download_terrain</code> and <code>convert_hgt_to_sdf</code>: to download and convert all the files needed for Splat!</li> <li><code>run_localtunnel</code>: to prepare and run the LocalTunnel with the given subdomain</li> <li><code>webhook_server</code>: to create the Flask server linked to the LocalTunnel</li> <li><code>calculate_igra</code>: to compute IGRA calculations and downloads</li> <li><code>era5_gradients</code>: to compute ERA5 calculations and downloads</li> <li><code>run_splat</code> and <code>generate_maps</code>: to make Splat! computations and generate the map.html </li> <li><code>main_stats</code>: to calculate statistics and plot graphs</li> </ul> <p>This script stores the processes launched to ensure a clean shutdown without leaving any processes still running or blocked.</p> <p>Then it fixes the ownership of folder <code>output</code> created to be owned by actual user.</p> <p>Calculations are scheduled and relaunched several times in throughout the day:</p> <ul> <li>Every 5 minutes for the Splat! computation and map.html writing (because end-node receives every 5 minutes)</li> <li>Twice a day (every 12 hours) for the IGRA computation</li> <li>Once a day (every 24 hours) for the ERA5 computation and for the statistics</li> </ul>"},{"location":"docker_documentation/#download_terrainpy","title":"download_terrain.py","text":"<p>This script is the first one launched and is used to download useful files (<code>.sdf</code> files) in order to the good use of Splat!.</p> <p>The Shuttle Radar Topography Mission (SRTM) files are all downloaded from https://www.usgs.gov/ by this mirror site as the USGS dataset is now unavailable.</p> <p>The script first take all tiles around for 3 degrees and guesses the region of the end-node (Africa, Australia, Eurasia, Islands, North-America, South-America) in order to go to the right directory for download.</p> <p>Then it downloads files named for example <code>N16E073.hgt.zip</code> at https://srtm.kurviger.de/SRTM3/Eurasia/N16E073.hgt.zip and unzip them under <code>/app/maps</code>.</p>"},{"location":"docker_documentation/#convert_hgt_to_sdfsh","title":"convert_hgt_to_sdf.sh","text":"<p>Used to convert the files downloaded by <code>download_terrain.py</code> into <code>SDF</code> (SPLAT Data Files) under <code>/app/maps</code> using the tool <code>srtm2sdf</code> from Splat!. (See Splat! Documentaion)</p> <p>See How to use splat</p>"},{"location":"docker_documentation/#run_localtunnelsh","title":"run_localtunnel.sh","text":"<p>Launches and maintain the LocalTunnel.</p> <p>Runs continuously and checks every minute if the tunnel is working by curling the URL, if not it then relaunches the tunnel.</p> <p>The tunnel is working on <code>localhost:5000</code>.</p>"},{"location":"docker_documentation/#webhook_serverpy","title":"webhook_server.py","text":"<p>This is the core of the application: the Flask server used as a webhook to retrieve data from https://console.helium-iot.xyz and to serve the generated maps online through the tunnel.</p> <p>It was first implemented by Marco RAINONE to test the retrieval of Helium data.</p> <p>It serves a server on <code>localhost:5000</code>. Helium data are automatically retrieved by using the HTTP integration (see doc) on the endpoint <code>helium-data</code> and filled in the <code>data/helium_gateway_data.csv</code>. The home route <code>/</code> only returns 'OK' to test the proper functioning with the previous script.</p> <p>A static map.html created can be served on <code>/map</code> but it is deprecated. Prefer using the route <code>/dynamic-map</code> that returns a simple HTML file using JavaScript fetchs to call the <code>/api</code> endpoint and retrieving useful data from the dataset.</p> <p>The script <code>dynamic_map.js</code> first fetch the configuration (coordinates of end-node) and all the gateway links, but in an optimized way, as well as the IGRA stations to show.</p> <p>This script also serves a route <code>/logs</code> to download the logs file of the application.</p> <p>Statistics are available at <code>/stats</code>.</p> <p>All other routes are used by the JavaScript to serve data or graphs.</p> <p>Here are all the routes created:</p> <ul> <li>/helium-data</li> <li>/api<ul> <li>/api/optimized_gateways</li> <li>/api/dates</li> <li>/api/igra_stations</li> <li>/api/gateways</li> <li>/api/config</li> <li>/api/era5_graph : used with arguments (lat, lon, date, time)</li> <li>/api/era5_daily_graph : used with argument (date)</li> </ul> </li> <li>/dynamic-map</li> <li>/map</li> <li>/app/output/igra-datas/derived/&lt;path:filename&gt;</li> <li>/plots/&lt;path:filename&gt;</li> <li>/plots</li> <li>/stats</li> </ul> <p>Note: Fetching the requested data for the requested day every time may take huge time and is not optimized. That is why the script is fetching all data once.</p>"},{"location":"docker_documentation/#calculate_igrapy","title":"calculate_igra.py","text":"<p>For detailled information about Integrated Global Radiosonde Archive (IGRA) version 2.2 see the doc and README. Here, the 'derived' section of this dataset is used as it gives directly refractivity measurements for each height.</p> <p>This script is used to automate the download of all useful data from FTP directory from National Centers for Environmental Information (NCEI). At the start of each launch, it makes sure to delete all old files in order to get the latest data. It gets the <code>igra2-station-list.txt</code> which lists all the station available and their last updates. Then, for each row of the dataset (corresponding to each link with gateways) it computes the spherical midpoint between this gateway and the end-node in order to find the nearest IGRA radiosonde to this point and download its latest data. The file contains all data from the beginning of the radiosonde's life until the last update (usually the day before), so this script parse the file to get all data for refractivity for all heights at the requested date.</p> <p>Finally, gradients are calculated and plotted into <code>output/igra-datas/derived/</code>, and a utility file <code>output/igra-datas/map_links.json</code> is created. This file is used to better and easily generate the static map.html (deprecated) by linking all gateways to their coordinates, nearest station, and URL path for graphs for all days. Its structure is like: <pre><code>{\n    \"gatewayID\": {\n        \"gateway_name\": name,\n        \"gateway_coords\": [lat, lon],\n        \"station_id\": IGRA_id,\n        \"station_coords\": [lat, lon],\n        \"midpoint\": [lat, lon],\n        \"graphs\": {\n            \"2025-06-06\": \"/app/output/igra-datas/derived/gradient_gatewayName_2025-06-06.png\",\n            ...\n        }\n    },\n    ...\n}\n</code></pre></p> <p>Graph plotted contain a small description on their values about different ducting cases (see <code>describe_ducting_case()</code>).</p> <p>A cache file <code>output/processed_gradients.json</code> is used to store already processed links in our dataset, so that for each relaunch, the script only compute new data. Its structure is something like: <pre><code>{\n    \"gatewayName1\": [\n        \"date1\",\n        \"date2\",\n        ...\n    ],\n    \"gatewayName2\": [\n        \"date1\",\n        ...\n    ],\n    ...\n}\n</code></pre></p> <p>Links that are noted <code>LOS</code> (in Line-Of-Sight) are skipped here as their graph are not useful in this research.</p>"},{"location":"docker_documentation/#era5_gradientspy","title":"era5_gradients.py","text":"<p>This script is the latest to have been created. It computes refractivity gradients in addition of IGRA data. It was thought to add more precise data in term of localisation and time as there are not so many IGRA stations around Europe.</p> <p>The dataset used for this project is the ERA5 hourly data on pressure levels from 1940 to present. (see Documentation of ERA5) Note: Daily updates for ERA5T are available about 5 days behind real time.</p> <p>An API is available with this ERA5 dataset and it is used in python with the module <code>cdsapi</code> (see Documentation of API).</p> <p>The basic utility of this script is to create a refractivity graph for each day with all available data. This means that it draws a gradient curve for each coordinate at each hour. Gradients that exceed the ducting threshold are displayed in red and annotated next to them.</p> <p>Here is an example of a daily gradient:</p> Daily ERA5 refractivity graph <p>Downloaded data are in GRIdded Binary (GRIB) format and downloaded individually for each day via the API. Data are for these pressure heights (in hPa): 1000, 950, 900, 850, 800, 750, 700; and for every two hours. In order to use the API, a config file <code>~/.cdsapirc</code> must be created and filled with these information (automated by the file):</p> <p><pre><code>cds_url = \"https://cds.climate.copernicus.eu/api\"  \ncds_key = \"799f5ea7...\"\n</code></pre> For this project, my personal cds_key is used.</p> <p>Another feature of this script is available: the on demand graph. This is called by the map's JavaScript by clicking on the button.  </p> ERA5 on demand button <p>This feature render two refractivity graphs by reading the corresponding GRIB file of the day and parsing it to find the requested hour (or the closest one). Rendered graphs are for the actual coordinates of the gateway and for the spherical midpoint between this gateway and the end-node, to remain consistent with IGRA's approach.  </p> On demand ERA5 graph <p>Note: Daily graphs are computed locally before exposing the map online, whereas on demand graphs are computed at the time of the call and will be stored locally until the next scheduled launch.</p>"},{"location":"docker_documentation/#run_splatpy","title":"run_splat.py","text":"<p>This script is used to make Splat! calls and create utility files for it to properly run.</p> <p>In the dataset of the links, every link is initially attributed <code>N/A</code> to the column <code>visibility</code>. This script is used to fill this column by either LOS (in Line-Of-Sight) or NLOS (not in Line-Of-Sight) depending on wheter the Line-Of-Sight is blocked by the Earth curvature or any object (mountains etc).</p> <p>For each gateway, it creates a Site Location (QTH) file containing the site's name, latitude, longitude and height above ground level, each separated by a single line-feed character. Caution: I have found that Splat! needs the longitudes to be written like this : lon = 360 - lon</p> <p>Here is an example of a QTH file named <code>abundant-mustard-snake.qth</code>:</p> <pre><code>abundant-mustard-snake\n44.1856944607886\n347.75593422313324\n3m\n</code></pre> <p>Then, it runs Splat! in terrain profile mode with point-to-point analysis to perform line-of-sight terrain analysis between the end-node and the gateway's location. (see Documentation) The command is <code>splat -t tx_site.qth -r rx_site.qth</code> with tx_site being the end-node so <code>end_node.qth</code> and rx_site being the gateway.</p> <p>Finally, it parses the analysis report text file by checking if the line \"detected obstructions at\" is present in it.</p> <p>Here are some examples of terrain analysis graphs returned by Splat:</p> In line of sight gateway (not blocked by environment) Not in line of sight gateway (blocked by environment) Not in line of sight gateway (blocked by Earth's curvature)"},{"location":"docker_documentation/#generate_mapspy","title":"generate_maps.py","text":"<p>This script is deprecated. It was first used to create the static map.html containing all necessary data to show the map.</p>"},{"location":"docker_documentation/#main_statspy","title":"main_stats.py","text":"<p>This script groups and manages all other scripts to calculate statistics in the <code>study-correlation/</code> folder: </p> <ul> <li>igra_ducts.py: for each day, detects all ducts with their minimal gradient, base height, top height and thickness and put it in <code>igra_ducts.csv</code></li> <li>daily_stats.py: for each day, calculates the total number of links, NLOS links, calculates NLOS ratio, average distance, maximum distance and number of different gateways and put it in <code>daily_propagation_stats.csv</code></li> <li>merge_data.py: just merge the two above dataset into one <code>merged_data.csv</code></li> <li>correlation.py: compute different type of correlation and plot results in <code>/app/web/static/stats/</code>. All these graphs are available at the <code>/stats</code> endpoint. Correlations are: Temporal analysis, Pearson correlation, Spearman correlation, linear regressions and correlation matrix.</li> </ul>"},{"location":"license/","title":"License","text":"<p>MIT License.</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p> <p>Copyright (c) 2025 Baptiste Demoisy. baptistedemoisy@gmail.com</p>"},{"location":"marconilab/","title":"MarconiLab Docker version","text":"<p>The MarconiLab, where this project was first launched, is running a different docker version on its servers.</p> <p>For security reasons, servers deny access to LocalTunnel. That is why Cloudflared tunnel is been used.</p>"},{"location":"python_documentation/","title":"Portable python version Documentation","text":"<p>The portable python version is the precursor to the next version made in Docker here.</p> <p>A Python toolkit to retrieve real-time datas from a LoRaWan end-node connected to the Helium network and to process IGRA v2 radiosonde data, compute atmospheric refractivity gradients, and visualize potential tropospheric ducts.</p>"},{"location":"python_documentation/#features","title":"Features","text":"<p>Here are the features it contains:</p> <ul> <li>Retrieve packets information and gateways received from the end-node</li> <li>Compute Splat! terrain point-to-point analysis to detect LOS/NLOS</li> <li>Find the nearest IGRA radiosonde from the gateway &lt;-&gt; end-node link's midpoint.</li> <li>Parse raw IGRA v2 data files (multi-level radiosonde observations)</li> <li>Compute refractivity (N) and its vertical gradient (\u0394N/\u0394h)</li> <li>Detect tropospheric ducts</li> <li>Generate vertical gradient graphs in PNG format</li> <li>Generate an interactive map showing all the gateways receiving the packets with their corresponding graphs</li> </ul>"},{"location":"python_documentation/#repository-structure","title":"Repository Structure","text":"<pre><code>/data/                      # Contains data retrieved from Helium\n\u251c\u2500\u2500  terrain/               #\u00a0QTH files for SPLAT\n\u251c\u2500\u2500  helium_data_msg.txt\n\u2514\u2500\u2500  helium_gateway_data.csv\n/igra-datas/                # Contains IGRA downloaded data and builded information for map\n\u251c\u2500\u2500 derived/                #\u00a0Contains refractivity graphs from derived measurements\n\u251c\u2500\u2500 igra2-station-list.txt\n\u2514\u2500\u2500 map_links.json\n/maps/                      # Contains .sdf and .hgt files for SPLAT's map\n/splat-runs/                # Contains .txt report files from SPLAT\n\u251c\u2500\u2500 img/                    # Contains terrain profiles and LOS between end-node and gateways\n\u2514\u2500\u2500 EndNode-to-gatewayName.txt\n/venv/                      # Python's virtual environment containing dependencies\ncalculate_igra.py\nconvert_hgt_to_sdf.sh\ngenerate_maps.py\nmain.py\nmap.html\nREADME.md\nrequirements.txt\nrun_localtunnel.sh\nrun_splat.py\nsetup.sh\nwebhook_server.py\n</code></pre>"},{"location":"release_notes/","title":"Release Notes","text":""},{"location":"release_notes/#docker-version","title":"Docker version","text":"<p>Get the release here. See Documentation</p>"},{"location":"release_notes/#python-portable-version","title":"Python portable version","text":"<p>Get the release here. See Documentation</p>"},{"location":"release_notes/#dockerhub-repository","title":"DockerHub repository","text":"<p>Access the repository here.</p>"},{"location":"setup_python/","title":"Portable python version setup","text":"<p>The portable python version has not been updated since this last release.</p>"},{"location":"setup_python/#prerequisites","title":"Prerequisites","text":"<p>You need to have an end-node connected to the Helium Network and create an HTTP integration on your application. Simply put the address you want to use for your LocalTunnel and remember it or write it down.</p> <p>Please follow the section Helium network setup of the Docker documentation.</p>"},{"location":"setup_python/#installation","title":"Installation","text":"<p>Go to the release and download the source zip and unzip it. Then run  <pre><code>cd LoRa-Helium-map\nsource setup.py yoursubdomain\n</code></pre></p> <p>With <code>yoursubdomain</code> being the subdomain you provided in your Helium HTTP integration. You will be asked to write your end-node's latitude and longitude.</p>"},{"location":"setup_python/#launch","title":"Launch","text":"<p>To launch the application, just run: <pre><code>python3 main.py\n</code></pre></p> <p>Or with logs showing on shell: <pre><code>python3 main.py --logs\n</code></pre></p>"},{"location":"setup_python/#results","title":"Results","text":"<p>The output map will be generated as <code>map.html</code> nad can be open with a web browser.</p> <p>All the gradients graphs can be found in <code>igra-datas/derived/</code>.</p>"},{"location":"setup_python/#example-output","title":"Example Output","text":"Interactive map example IGRA gradient example"}]}